{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09668d6f",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce02aec-c157-4777-8e2f-ba64852eea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/abdffsm/miniconda/envs/llm-pred/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model_name = {\n",
    "  \"phi-2\": \"microsoft/phi-2\",\n",
    "  \"phi-3\": \"microsoft/Phi-3-mini-4k-instruct\", \n",
    "  \"mistral\": \"mistralai/Mistral-7B-v0.3\"\n",
    "}\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name[\"phi-2\"], torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name[\"phi-2\"], trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa45c4d9",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65eb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# numpy random generator \n",
    "random_generator = np.random.default_rng()\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "timing_data = pd.read_csv('../data/timing_data.csv')\n",
    "\n",
    "# filter by model name \n",
    "df_gpt3 = timing_data[timing_data['model'].str.contains('gpt3')]\n",
    "df_gpt4 = timing_data[timing_data['model'].str.contains('gpt-4')]\n",
    "df_gpt4_new = timing_data[timing_data['model'].str.contains('gpt4-new')]\n",
    "df_claude_opus = timing_data[timing_data['model'].str.contains('claude-3-opus')]\n",
    "df_claude_sonnet = timing_data[timing_data['model'].str.contains('claude-3-sonnet')] \n",
    "df_claude_haiku = timing_data[timing_data['model'].str.contains('claude-3-haiku')] \n",
    "\n",
    "dataframes = [df_gpt3, df_gpt4, df_gpt4_new, df_claude_opus, df_claude_sonnet, df_claude_haiku]\n",
    "\n",
    "def is_standard_english(text):\n",
    "    # This regex pattern matches standard English characters, numbers, and basic punctuation\n",
    "    pattern = r'^[a-zA-Z0-9\\s.,!?()-]+$'\n",
    "    return bool(re.match(pattern, str(text))) \n",
    "\n",
    "for df_index, df in enumerate(dataframes):\n",
    "    # eliminate outliers\n",
    "    dataframes[df_index] = df[df['time_taken (s)'] < 1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a91d367",
   "metadata": {},
   "source": [
    "# Select samples and generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "219d6e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193090/2903531686.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_gpt3 = df_gpt3.applymap(lambda x: x if is_standard_english(x) else None)\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a prompt, respond in the same length as GPT-3.5 does. \n",
      "\n",
      "\n",
      "Here are some examples. Each example consists of a prompt and a response. \n",
      "\n",
      "\n",
      "Prompt1: Whats the best playground for kids near me\n",
      "\n",
      "\n",
      "GPT Response1: You can use apps like Google Maps or Yelp to find the best playgrounds near your location. Look for ones with good reviews and plenty of fun activities for kids!\n",
      "\n",
      "\n",
      "Prompt2: Hi\n",
      "\n",
      "\n",
      "GPT Response2: Hello! How can I assist you today?\n",
      "\n",
      "\n",
      "Prompt3: How many bridges connect nj to NYC?\n",
      "\n",
      "\n",
      "GPT Response3: There are actually several bridges that connect New Jersey to New York City! Some of the most well-known ones include the George Washington Bridge, the Lincoln Tunnel, and the Holland Tunnel. These bridges and tunnels serve as vital connections for commuters and travelers between the two states. If you plan on crossing any of these, make sure to have your EZPass ready!\n",
      "\n",
      "\n",
      "Prompt4: Hi\n",
      "\n",
      "\n",
      "GPT Response4: Hello! How can I assist you today? If you have any questions or need information, feel free to ask.\n",
      "\n",
      "\n",
      "Prompt5: Hey\n",
      "\n",
      "\n",
      "GPT Response5: Hey there! What can I help you with today?\n",
      "\n",
      "\n",
      "Prompt6: Why are some lamps\n",
      "White and some yellow?\n",
      "\n",
      "\n",
      "GPT Response6: The color of light from a lamp depends on the type of bulb used. White light is typically associated with LED bulbs, while yellowish light is often produced by incandescent bulbs. The difference in color temperature can also impact the ambiance of a room. Think of it as choosing between a bright, energizing atmosphere (white light) and a cozy, warm vibe (yellow light). Each has its own charm!\n",
      "\n",
      "\n",
      "Prompt7: Hi\n",
      "\n",
      "\n",
      "GPT Response7: Hey there! How can I help you today?\n",
      "\n",
      "\n",
      "Prompt8: Does Somali food include banana with every dish?\n",
      "\n",
      "\n",
      "GPT Response8: While bananas are a popular and commonly enjoyed fruit in Somalia, they are not necessarily included with every dish in Somali cuisine. However, bananas do feature prominently in some traditional Somali recipes and are often used in desserts, smoothies, and as a side dish or accompaniment to savory meals.\n",
      "\n",
      "In Somali cuisine, bananas are sometimes used in stews and meat dishes, adding a hint of natural sweetness to the savory flavors. Additionally, ripe bananas are frequently incorporated into sweet treats like cakes, pastries, and puddings, showcasing their versatility in both sweet and savory culinary applications.\n",
      "\n",
      "So, while bananas are not a mandatory component of every Somali dish, they do play a significant role in adding unique flavor and texture to certain meals, making them a delightful and adaptable ingredient in Somali cuisine.\n",
      "\n",
      "\n",
      "Prompt9: Why has ZTBL failed as an agriculture bank\n",
      "\n",
      "\n",
      "GPT Response9: The failure of Zari Tariqiati Bank Limited (ZTBL) as an agricultural bank can be attributed to various factors such as mismanagement, inefficient lending practices, lack of modernization, and ineffective implementation of policies. Additionally, issues related to loan recovery, governance, and adaptation to changing agricultural needs have also contributed to its challenges.\n",
      "\n",
      "Efforts to reform and address these issues are essential for ZTBL to fulfill its intended role effectively and support the agricultural sector in Pakistan.\n",
      "\n",
      "If you have more questions or need further insights, feel free to ask!\n",
      "\n",
      "\n",
      "Prompt10: hi\n",
      "\n",
      "\n",
      "GPT Response10: Hello again! How can I help you today?\n",
      "\n",
      "\n",
      "Now, the prompt for you to predict is: Kya aapko lagta hai ki misunderstandings aur conflicts ko resolve karne ke liye effective communication ka kya role hota hai?\n",
      "\n",
      "\n",
      "GPT Response11: Effective communication plays a crucial role in resolving misunderstandings and conflicts. When individuals engage in open and honest communication, they can express their thoughts, feelings, and concerns clearly, leading to a better understanding of each other's perspectives.\n",
      "\n",
      "Active listening, empathy, and respect are essential components of effective communication. By actively listening to others, we can understand their viewpoints and validate their emotions. Empathy allows us to put ourselves in someone else's shoes and understand their experiences and feelings. Respect ensures that we treat others with dignity and value their opinions.\n",
      "\n",
      "When conflicts arise, effective communication can help in finding common ground, identifying the root causes of the conflict, and working towards a mutually beneficial resolution. It allows individuals to express their needs and concerns, negotiate compromises, and find solutions that address the underlying issues.\n",
      "\n",
      "In conclusion, effective communication is a powerful tool in resolving misunderstandings and conflicts. By fostering open and respectful dialogue, individuals can build stronger relationships, promote understanding, and work towards peaceful resolutions.\n",
      "<|endoftext|>\n",
      "\n",
      "\n",
      "\n",
      " --------------- \n",
      "\n",
      "\n",
      "\n",
      "Ground truth: \n",
      "Bilkul! Misunderstandings se shuru hokar conflicts mein badalne se bachne ke liye effective communication ka bahut bada role hota hai. Jab hum clearly aur respectfully apne thoughts, feelings aur perspectives ko express karte hain, tab dusre vyakti ko samajhne mein madad milti hai. Isse miscommunication ki chances kam hoti hain aur situation ko samjhne mein madad milti hai. Isi tarah, dono taraf se open communication misunderstandings ko resolve karne mein madad karti hai. Agar aap kisi specific situation ke baare mein soch rahe hain toh main aur bhi madad kar sakta hoon.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Randomly select samples\n",
    "examples = []\n",
    "example_num = 10\n",
    "# Delete non-standard characters \n",
    "df_gpt3 = df_gpt3.applymap(lambda x: x if is_standard_english(x) else None)\n",
    "df_gpt3 = df_gpt3.dropna()\n",
    "df_gpt3_sample = df_gpt3.sample(n=example_num+1, random_state=random_generator)\n",
    "# Get the last row of the DataFrame\n",
    "df_gpt3_input = df_gpt3_sample.iloc[-1]\n",
    "# Get all the rows but the last one\n",
    "df_gpt3_example = df_gpt3_sample.iloc[:-1]\n",
    "# Iterate through the DataFrame with index starting from 0 \n",
    "for index, data in enumerate(df_gpt3_example.iterrows()):\n",
    "    current_example = \"\"\n",
    "    current_example += \"Prompt\" + str(index + 1) + \": \" + data[1]['prompt'] + \"\\n\\n\\n\"\n",
    "    current_example += \"GPT Response\" + str(index + 1) + \": \" + data[1]['response'] + \"\\n\\n\\n\"\n",
    "    examples.append(current_example)\n",
    "\n",
    "sys_prompt = \"\"\"Given a prompt, respond in the same length as GPT-3.5 does. \\n\\n\\n\"\"\"\n",
    "example_prompt = \"\"\"Here are some examples. Each example consists of a prompt and a response. \\n\\n\\n\"\"\"\n",
    "for example in examples:\n",
    "    example_prompt += example\n",
    "input = \"\"\"Now, the prompt for you to predict is: \"\"\" + df_gpt3_input['prompt'] + \"\\n\\n\\n\"\n",
    "prompt = sys_prompt + example_prompt + input\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 1000)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)\n",
    "\n",
    "print (\"\\n\\n\\n --------------- \\n\\n\\n\")\n",
    "\n",
    "print(\"Ground truth: \\n\" + df_gpt3_input['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8fded0",
   "metadata": {},
   "source": [
    "## Pull data and export spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
