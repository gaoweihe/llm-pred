{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09668d6f",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce02aec-c157-4777-8e2f-ba64852eea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaowh/.conda/envs/llm-pred/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/gaowh/.conda/envs/llm-pred/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.82s/it]\n",
      "/home/gaowh/.conda/envs/llm-pred/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa45c4d9",
   "metadata": {},
   "source": [
    "## Prepare examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65eb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "timing_data = pd.read_csv('../data/timing_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a006fd",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef1b339d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict the number of output tokens from GPT-3.5. Output a number only, without any other texts. Here are some examples. Example 1: Question: For international students coming to the US, which city is better overall: Los Angeles or Boston? Answer: Ah, the classic tug-of-war between the glitz of Los Angeles and the charm of Boston! ðŸŒŸ Both cities offer unique experiences for international students, but it ultimately depends on your preferences.Now, the prompt for you to predict is: For international students coming to the US, which city is better overall: Los Angeles or Boston?\n",
      "Output: The number of output tokens from GPT-3.5 is 2.\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "sys_prompt = r'Predict the number of output tokens from GPT-3.5. Output a number only, without any other texts. '\n",
    "examples = r'Here are some examples. Example 1: Question: For international students coming to the US, which city is better overall: Los Angeles or Boston? Answer: Ah, the classic tug-of-war between the glitz of Los Angeles and the charm of Boston! ðŸŒŸ Both cities offer unique experiences for international students, but it ultimately depends on your preferences.'\n",
    "input = r'Now, the prompt for you to predict is: For international students coming to the US, which city is better overall: Los Angeles or Boston?'\n",
    "prompt = sys_prompt + examples + input\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "outputs = model.generate(**inputs, max_length = 1000)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8fded0",
   "metadata": {},
   "source": [
    "## Pull data and export spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
