{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce02aec-c157-4777-8e2f-ba64852eea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef1b339d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want you to generate a love letter for me. \n",
      "\n",
      "(Name)\n",
      "##OUTPUT\n",
      "My dearest (Name),\n",
      "\n",
      "I hope this letter finds you well. I wanted to take a moment to express my deepest love and affection for you. You are the light of my life, the reason for my smile, and the source of my happiness. Your love has brought so much joy and fulfillment into my life, and I am forever grateful for your presence. I love you more than words can ever express.\n",
      "\n",
      "With all my heart,\n",
      "\n",
      "(Name)\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "sys_prompt = r'I want you to generate a love letter for me. '\n",
    "examples = r''\n",
    "prompt = sys_prompt + examples\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=1000)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
